---
title: "Course-Correction: Safety Alignment Using Synthetic Preferences.   EMNLP 2024 Industry Track.   The risk of harmful contents generated by large language models (LLMs) becomes a critical concern. This paper systematically evaluates and enhances LLMs' capability to perform \emph{course-correction}, \ie, the model can steer away from generating harmful content autonomously. First, we introduce the C-Eval benchmark for quantitative assessment and analyze 10 popular LLMs, revealing varying proficiency of current safety-tuned LLMs in course-correction. To improve, we propose fine-tuning LLMs with preference learning, emphasizing the preference for timely course-correction. Using an automated pipeline, we create C-Syn, a synthetic C-Syn with 750K pairwise preferences, to teach models the concept of timely course-correction through data-driven learning. Experiments on \textsc{Llama2-Chat 7B} and \textsc{Qwen2 7B} show that our method effectively enhances course-correction skills without affecting general performance. Additionally, it effectively improves LLMs' safety, particularly in resisting jailbreak attacks."
collection: publications
permalink: /publication/2024-10-02-http://academicpages.github.io/files/slides1.pdf
excerpt: 'course-correction-safety-alignment-using-synthetic-preferences'
date: 2024-10-02
venue: 'Your Name, You. (2024). &quot;Course-Correction: Safety Alignment Using Synthetic Preferences.&quot; <i>EMNLP 2024 Industry Track</i>. 1(1).'
citation: 'http://academicpages.github.io/files/paper1.pdf'
---
course-correction-safety-alignment-using-synthetic-preferences

Recommended citation: http://academicpages.github.io/files/paper1.pdf